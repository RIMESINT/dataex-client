{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dataex API A dataex API client library for: Download and insertion of observation data. Download summary of observation data. Download raw netcdf data of ECMWF HRES/ENS/SEAS forecasts for specific region and parameter. List reducer names and user assets available for forecast data analysis. Download region specific forecast timeseries of ECMWF ENS/HRES/SEAS model forecasts. Installation Dataex API client can be installed using the following command, pip install https://github.com/nzahasan/dataex-client/zipball/master Commands dataex_init.py - Create .dataex_auth.json file for dataex user authentication dataex_netcdf_subset.py - Download raw netcdf subset of ECMWF HRES/ENS/SEAS model forecasts. dataex_list_country_info.py - List information of countries dataex_obs_station_list.py - List station(s) information of a specific country dataex_get_obs_data.py - Download observation data. dataex_insert_obs_data.py - Upload observation data. dataex_obs_data_summary.py - Download summary of observation data. dataex_obs_parameter_list.py - Retrieve a list of parameter information of a specific station dataex_list_user_assets.py - List user assets available to use in forecast analysis dataex_list_reducers.py - List reducer names available for use in forecast analysis dataex_region_data_analysis.py - Download region specific forecast time series of ECMWF HRES/ENS/SEAS model forecasts. Example Let's take a look at a quick example of one of the above commands. It's as easy as typing the command into your favourite terminal. Suppose we want to download a netCDF subset file from model hres for parameters u10, swvl1, t2m . We can use the following command, $ dataex_netcdf_subset.py --model_type hres --params u10,swvl1,t2m --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc Alternatively, you can use short forms of the option names used in the above command. Support For support please email us at support@rimes.int. Make sure to include the specific problem in the subject of the mail. Security If you believe you've found something in the dataex client API which has security implications, pleas send a description of the issue via email to support@rimes.int. License MIT License Copyright \u00a9 2021 RIMES Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Home"},{"location":"#dataex-api","text":"A dataex API client library for: Download and insertion of observation data. Download summary of observation data. Download raw netcdf data of ECMWF HRES/ENS/SEAS forecasts for specific region and parameter. List reducer names and user assets available for forecast data analysis. Download region specific forecast timeseries of ECMWF ENS/HRES/SEAS model forecasts.","title":"Dataex API"},{"location":"#installation","text":"Dataex API client can be installed using the following command, pip install https://github.com/nzahasan/dataex-client/zipball/master","title":"Installation"},{"location":"#commands","text":"dataex_init.py - Create .dataex_auth.json file for dataex user authentication dataex_netcdf_subset.py - Download raw netcdf subset of ECMWF HRES/ENS/SEAS model forecasts. dataex_list_country_info.py - List information of countries dataex_obs_station_list.py - List station(s) information of a specific country dataex_get_obs_data.py - Download observation data. dataex_insert_obs_data.py - Upload observation data. dataex_obs_data_summary.py - Download summary of observation data. dataex_obs_parameter_list.py - Retrieve a list of parameter information of a specific station dataex_list_user_assets.py - List user assets available to use in forecast analysis dataex_list_reducers.py - List reducer names available for use in forecast analysis dataex_region_data_analysis.py - Download region specific forecast time series of ECMWF HRES/ENS/SEAS model forecasts.","title":"Commands"},{"location":"#example","text":"Let's take a look at a quick example of one of the above commands. It's as easy as typing the command into your favourite terminal. Suppose we want to download a netCDF subset file from model hres for parameters u10, swvl1, t2m . We can use the following command, $ dataex_netcdf_subset.py --model_type hres --params u10,swvl1,t2m --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc Alternatively, you can use short forms of the option names used in the above command.","title":"Example"},{"location":"#support","text":"For support please email us at support@rimes.int. Make sure to include the specific problem in the subject of the mail.","title":"Support"},{"location":"#security","text":"If you believe you've found something in the dataex client API which has security implications, pleas send a description of the issue via email to support@rimes.int.","title":"Security"},{"location":"#license","text":"MIT License Copyright \u00a9 2021 RIMES Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"quick_start/","text":"We are going to set up a vitual environment to use the dataex client. Installation This is the quickest and easiest way to install the API. You can then start using the scripts right away. pip install https://github.com/nzahasan/dataex-client/zipball/master Using a virtual environment If you want to isolate the environment for the datex client module from your system wide environment, then using python virtual environment is the best way going forward. Installing python virtualenv If you don't already have it then use the following command to install. $ pip install virtualenv But with Python 3, you should already have the venv module from the standard library installed. Creating a virtual environment $ python3 -m venv env On python 3.6 and above, this is the recommended way to go. The \"env\" is the name of the virtual environment. You can change it according to your preference. In order to use the environment, you have to activate it. $ source env/bin/activate (env) $ The env within the parenthesis means that you are now using the virtual environment. If you need to go back to the system context then just execute deactivate. (env) $ deactivate $ With this your shell session reverts to normal with python commands referring to the global python install. Finally, run the above pip install command while activating the virtual environment to create an isolated python context that is not going to affect your global python setting. Running a command (env)$ dataex_obs_data_summary.py --output ./summary.csv --output_type csv There is no difference in the way a command is used. But now you have the advantage of running it inside its own isolated environment.","title":"Using virtual environment"},{"location":"quick_start/#installation","text":"This is the quickest and easiest way to install the API. You can then start using the scripts right away. pip install https://github.com/nzahasan/dataex-client/zipball/master","title":"Installation"},{"location":"quick_start/#using-a-virtual-environment","text":"If you want to isolate the environment for the datex client module from your system wide environment, then using python virtual environment is the best way going forward.","title":"Using a virtual environment"},{"location":"quick_start/#installing-python-virtualenv","text":"If you don't already have it then use the following command to install. $ pip install virtualenv But with Python 3, you should already have the venv module from the standard library installed.","title":"Installing python virtualenv"},{"location":"quick_start/#creating-a-virtual-environment","text":"$ python3 -m venv env On python 3.6 and above, this is the recommended way to go. The \"env\" is the name of the virtual environment. You can change it according to your preference. In order to use the environment, you have to activate it. $ source env/bin/activate (env) $ The env within the parenthesis means that you are now using the virtual environment. If you need to go back to the system context then just execute deactivate. (env) $ deactivate $ With this your shell session reverts to normal with python commands referring to the global python install. Finally, run the above pip install command while activating the virtual environment to create an isolated python context that is not going to affect your global python setting.","title":"Creating a virtual environment"},{"location":"quick_start/#running-a-command","text":"(env)$ dataex_obs_data_summary.py --output ./summary.csv --output_type csv There is no difference in the way a command is used. But now you have the advantage of running it inside its own isolated environment.","title":"Running a command"},{"location":"user-guide/dataex_get_obs_data/","text":"Get Observation Data CLI This script is for downloading observation data from Dataex server. Users can get the desired observation data in the selected format for a specific observation parameter and station. Usage $ dataex_get_obs_data.py --start_date <YYYY-MM-DD> --end_date <YYYY-MM-DD> -- station_id <int> --parameter_id <int> --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options parameter_id : int parameter id start_date : DateTime Date in YYYY-MM-DD format end_date : DateTime Date in YYYY-MM-DD format station_id : int station id output_type : str json, table or csv output : str output filename Output type and output options are not required. The default output type is table . Info Users can get station and parameter id numbers using dataex_obs_station_list.py and dataex_obs_parameter_list.py respectively. Example $ get_obs_data.py --start_date 1994-11-01 --end_date 1994-12-10 -- stn_id 11 --p_id 4 --output_type csv --output ./obs_data.csv It goes without saying that the start_date must be a date that is earlier than the end_date . The time period should be within 180 days. Info In case the time period is beyond 180 days, the server just returns a truncated observation dataset of 180 days instead. $ get_obs_data.py --start_date 1994-11-01 --end_date 1994-12-10 -- stn_id 11 --p_id 4 Here, observation data will be displayed in tabular form in the terminal.","title":"Download observation data"},{"location":"user-guide/dataex_get_obs_data/#get-observation-data-cli","text":"This script is for downloading observation data from Dataex server. Users can get the desired observation data in the selected format for a specific observation parameter and station.","title":"Get Observation Data CLI"},{"location":"user-guide/dataex_get_obs_data/#usage","text":"$ dataex_get_obs_data.py --start_date <YYYY-MM-DD> --end_date <YYYY-MM-DD> -- station_id <int> --parameter_id <int> --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_get_obs_data/#options","text":"parameter_id : int parameter id start_date : DateTime Date in YYYY-MM-DD format end_date : DateTime Date in YYYY-MM-DD format station_id : int station id output_type : str json, table or csv output : str output filename Output type and output options are not required. The default output type is table . Info Users can get station and parameter id numbers using dataex_obs_station_list.py and dataex_obs_parameter_list.py respectively.","title":"Options"},{"location":"user-guide/dataex_get_obs_data/#example","text":"$ get_obs_data.py --start_date 1994-11-01 --end_date 1994-12-10 -- stn_id 11 --p_id 4 --output_type csv --output ./obs_data.csv It goes without saying that the start_date must be a date that is earlier than the end_date . The time period should be within 180 days. Info In case the time period is beyond 180 days, the server just returns a truncated observation dataset of 180 days instead. $ get_obs_data.py --start_date 1994-11-01 --end_date 1994-12-10 -- stn_id 11 --p_id 4 Here, observation data will be displayed in tabular form in the terminal.","title":"Example"},{"location":"user-guide/dataex_init/","text":"Create dataex auth file CLI It is a script to be used for creating the .dataex_auth.json file. The user is prompted to enter dataex username and password in the terminal after running this command. Usage $ dataex_init.py Executing this command creates a hidden file that is stored in the home directory which will be used for authentication. The user must already have a registered dataex account. To avoid rejection, users must first visit the website and then create a dataex user account. Info However, not running this command in the beginning will not impede the usage of other scripts. This is possible because auth module can also create the authentication file if one is not already present.","title":"How to initialize dataex"},{"location":"user-guide/dataex_init/#create-dataex-auth-file-cli","text":"It is a script to be used for creating the .dataex_auth.json file. The user is prompted to enter dataex username and password in the terminal after running this command.","title":"Create dataex auth file CLI"},{"location":"user-guide/dataex_init/#usage","text":"$ dataex_init.py Executing this command creates a hidden file that is stored in the home directory which will be used for authentication. The user must already have a registered dataex account. To avoid rejection, users must first visit the website and then create a dataex user account. Info However, not running this command in the beginning will not impede the usage of other scripts. This is possible because auth module can also create the authentication file if one is not already present.","title":"Usage"},{"location":"user-guide/dataex_insert_obs_data/","text":"Insert observation data CLI This script allows the user to upload observation data into Dataex server. It takes as input either a csv or excel file containing the observations along with the country id number as the command arguments. Info To get the country id numbers, you can use dataex_list_country_info.py command. Usage $ dataex_insert_obs_data.py --country_id <int> --obs_data <str> Tip Option names too long, you can always use their short forms. Check using --help Options country_id : int id number of country obs_data : str input file either csv or excel Example $ dataex_insert_obs_data.py --country_id 5 --obs_data ./input.csv Here, the input observation data is provided in csv format using --obs_data option. Input file details The column headers in both csv and excels must be: start_time, end_time, value, level_id, parameter_id and station_id Start and end time denote the date of recorded observation. Accumulated parameters have different start and end times while instant parameters have the same start and end times. Every parameter has a distinct id. The level id is used for identifying observation levels such as surface level, 2m or 10 m. Every station has a unique id assigned to it. The time values must be in YYYY-MM-DD HH:MM format for both csv and excel files. Warning Please adhere strictly to the format below used in the examples for successful execution of the command. CSV file format start_time,end_time,value,level_id,parameter_id,station_id 1995-01-01 00:00,1995-01-02 00:00,30.2,2,3,54 1996-01-01 00:00,1996-01-02 00:00,28.2,2,3,54 Excel file format start_time end_time value level_id parameter_id station_id 1995-01-01 00:00 1995-01-02 00:00 30.2 2 3 54 1996-01-01 00:00 1996-01-02 00:00 28.2 2 3 54","title":"Upload observation data"},{"location":"user-guide/dataex_insert_obs_data/#insert-observation-data-cli","text":"This script allows the user to upload observation data into Dataex server. It takes as input either a csv or excel file containing the observations along with the country id number as the command arguments. Info To get the country id numbers, you can use dataex_list_country_info.py command.","title":"Insert observation data CLI"},{"location":"user-guide/dataex_insert_obs_data/#usage","text":"$ dataex_insert_obs_data.py --country_id <int> --obs_data <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_insert_obs_data/#options","text":"country_id : int id number of country obs_data : str input file either csv or excel","title":"Options"},{"location":"user-guide/dataex_insert_obs_data/#example","text":"$ dataex_insert_obs_data.py --country_id 5 --obs_data ./input.csv Here, the input observation data is provided in csv format using --obs_data option.","title":"Example"},{"location":"user-guide/dataex_insert_obs_data/#input-file-details","text":"The column headers in both csv and excels must be: start_time, end_time, value, level_id, parameter_id and station_id Start and end time denote the date of recorded observation. Accumulated parameters have different start and end times while instant parameters have the same start and end times. Every parameter has a distinct id. The level id is used for identifying observation levels such as surface level, 2m or 10 m. Every station has a unique id assigned to it. The time values must be in YYYY-MM-DD HH:MM format for both csv and excel files. Warning Please adhere strictly to the format below used in the examples for successful execution of the command.","title":"Input file details"},{"location":"user-guide/dataex_insert_obs_data/#csv-file-format","text":"start_time,end_time,value,level_id,parameter_id,station_id 1995-01-01 00:00,1995-01-02 00:00,30.2,2,3,54 1996-01-01 00:00,1996-01-02 00:00,28.2,2,3,54","title":"CSV file format"},{"location":"user-guide/dataex_insert_obs_data/#excel-file-format","text":"start_time end_time value level_id parameter_id station_id 1995-01-01 00:00 1995-01-02 00:00 30.2 2 3 54 1996-01-01 00:00 1996-01-02 00:00 28.2 2 3 54","title":"Excel file format"},{"location":"user-guide/dataex_list_country_info/","text":"Get Country Info CLI It can be used to retrieve information such as Id number related to a specific country or all countries available on Dataex. Usage $ dataex_list_country_info.py --country <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options: output_format : str json, table or csv country : str name of country output : str output filename The default output format is table . Hence, leaving this option out from the command is not a problem. The output option is not required as well. Example $ dataex_list_country_info.py --country Bangladesh --output_format json --output ./country_info.json Here, a json file with country information is downloaded. $ dataex_list_country_info.py All country data is downloaded and shown in tabular form. $ dataex_list_country_info.py --country Nepal This downloads and displays information on the terminal in table format for Nepal. Tip If country option is not provided then information on all countries in the dataex is downloaded which can be saved in an output file.","title":"List countries"},{"location":"user-guide/dataex_list_country_info/#get-country-info-cli","text":"It can be used to retrieve information such as Id number related to a specific country or all countries available on Dataex.","title":"Get Country Info CLI"},{"location":"user-guide/dataex_list_country_info/#usage","text":"$ dataex_list_country_info.py --country <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options: output_format : str json, table or csv country : str name of country output : str output filename The default output format is table . Hence, leaving this option out from the command is not a problem. The output option is not required as well.","title":"Usage"},{"location":"user-guide/dataex_list_country_info/#example","text":"$ dataex_list_country_info.py --country Bangladesh --output_format json --output ./country_info.json Here, a json file with country information is downloaded. $ dataex_list_country_info.py All country data is downloaded and shown in tabular form. $ dataex_list_country_info.py --country Nepal This downloads and displays information on the terminal in table format for Nepal. Tip If country option is not provided then information on all countries in the dataex is downloaded which can be saved in an output file.","title":"Example"},{"location":"user-guide/dataex_list_reducers/","text":"Check reducers CLI This script allows the user to list all the available reducer names that can be used in forecast analysis depending on the model type: HRES ENS SEAS Usage $ dataex_list_reducers.py --model_type <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options output_format : str json, table, csv model_type : str model name output : str output filename For model types, HRES is the default. --output_format option if not used, defaults to table and then the downloaded data is displayed on terminal in case output option is also left out. Info The model type names are case-insensitive. For instance, hres or HRES are both valid. Example $ dataex_check_reducers.py --output_format json --output ./reducers.json Here, a json file stores the downloaded data. The model type is HRES since it is the default. $ dataex_check_reducers.py --model_type ENS Model type is specified as ENS . The output format is table which is the default.","title":"List reducers"},{"location":"user-guide/dataex_list_reducers/#check-reducers-cli","text":"This script allows the user to list all the available reducer names that can be used in forecast analysis depending on the model type: HRES ENS SEAS","title":"Check reducers CLI"},{"location":"user-guide/dataex_list_reducers/#usage","text":"$ dataex_list_reducers.py --model_type <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_list_reducers/#options","text":"output_format : str json, table, csv model_type : str model name output : str output filename For model types, HRES is the default. --output_format option if not used, defaults to table and then the downloaded data is displayed on terminal in case output option is also left out. Info The model type names are case-insensitive. For instance, hres or HRES are both valid.","title":"Options"},{"location":"user-guide/dataex_list_reducers/#example","text":"$ dataex_check_reducers.py --output_format json --output ./reducers.json Here, a json file stores the downloaded data. The model type is HRES since it is the default. $ dataex_check_reducers.py --model_type ENS Model type is specified as ENS . The output format is table which is the default.","title":"Example"},{"location":"user-guide/dataex_list_user_assets/","text":"Get user fcst asset info CLI This script enables the user to list all the available forecast analysis user assets. Usage $ dataex_get_user_assets.py The available user assets are shown in tabluar form in the terminal. Sample The following is a sample of the output shown: file identifier info user_asset/some_district_shape.geojson 78440ef2-1deb-40c0-96b8-9b0953d6absdf4 {'rec_count': 90, 'unique_fields': ['ADM2_EN', 'ADM2_PCODE']} user_asset/some_District_.json c3ac4c6d-ccf4-42fc-8f15-826f51dsaff8 {'rec_count': 90, 'unique_fields': ['ID_2', 'NAME_2']}","title":"List user assets"},{"location":"user-guide/dataex_list_user_assets/#get-user-fcst-asset-info-cli","text":"This script enables the user to list all the available forecast analysis user assets.","title":"Get user fcst asset info CLI"},{"location":"user-guide/dataex_list_user_assets/#usage","text":"$ dataex_get_user_assets.py The available user assets are shown in tabluar form in the terminal.","title":"Usage"},{"location":"user-guide/dataex_list_user_assets/#sample","text":"The following is a sample of the output shown: file identifier info user_asset/some_district_shape.geojson 78440ef2-1deb-40c0-96b8-9b0953d6absdf4 {'rec_count': 90, 'unique_fields': ['ADM2_EN', 'ADM2_PCODE']} user_asset/some_District_.json c3ac4c6d-ccf4-42fc-8f15-826f51dsaff8 {'rec_count': 90, 'unique_fields': ['ID_2', 'NAME_2']}","title":"Sample"},{"location":"user-guide/dataex_netcdf_subset/","text":"Get NetCDF Subset CLI This script allows the user to get a netCDF subset of model type: HRES ENS SEAS Usage $ dataex_netcdf_subset.py --model_type <str> --hres_params <str>,<str> --latbounds <float> <float> --lonbounds <float> <float> --output <str> $ dataex_netcdf_subset.py --model_type <str> --ens_params <str> --latbounds <float> <float> --lonbounds <float> <float> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options hres_params : str Use for single or comma seperated HRES parameter short names ens_params : str Use for single or comma seperated ENS parameter short names model_type : str model name latbounds : float values South and North latitutde values space seperated lonbounds : float values West and East longitude values space seperated params : str or list of str Single or comma seperated parameter short names output : str output filename Warning Latitude and longitude values outside the available dataset boundaries will return an error. List of parameters in ECMWF HRES The following parameters are available for subsetting in ECMWF HRES , u10, ssr, str, sshf, slhf, d2m, v10, t2m, cp, lsp, swvl1,swvl2, swvl3, swvl4 List of parameters in ECMWF ENS The following parameters are available for subsetting in ECMWF ENS , cp_q5, cp_q25, cp_q50, cp_q75, cp_q95, t2m_q5, t2m_q25, t2m_q50, t2m_q75, t2m_q95, lsp_q5, lsp_q25, lsp_q50, lsp_q75, lsp_q95 There are five quantiles available for each parameter in ECMWF ENS . Example $ dataex_netcdf_subset.py --model_type hres --hres_params u10,swvl1,t2m --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc The model type input is case-insensitive. Here, only three parameters are provided. The hres_params denotes the parameters are intended for hres model. If the parameters are not provided then all model parameters are placed in the request. $ dataex_netcdf_subset.py --model_type ens --ens_params cp_q25 --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc This one is for requesting netcdf data of model ens . Here, ens_params denotes the parameters are for model ens . Info Don't fret if you make a mistake by using the incorrect parameter option, the command refers to the model type selected and uses the related parameters.","title":"Download NetCDF"},{"location":"user-guide/dataex_netcdf_subset/#get-netcdf-subset-cli","text":"This script allows the user to get a netCDF subset of model type: HRES ENS SEAS","title":"Get NetCDF Subset CLI"},{"location":"user-guide/dataex_netcdf_subset/#usage","text":"$ dataex_netcdf_subset.py --model_type <str> --hres_params <str>,<str> --latbounds <float> <float> --lonbounds <float> <float> --output <str> $ dataex_netcdf_subset.py --model_type <str> --ens_params <str> --latbounds <float> <float> --lonbounds <float> <float> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_netcdf_subset/#options","text":"hres_params : str Use for single or comma seperated HRES parameter short names ens_params : str Use for single or comma seperated ENS parameter short names model_type : str model name latbounds : float values South and North latitutde values space seperated lonbounds : float values West and East longitude values space seperated params : str or list of str Single or comma seperated parameter short names output : str output filename Warning Latitude and longitude values outside the available dataset boundaries will return an error.","title":"Options"},{"location":"user-guide/dataex_netcdf_subset/#list-of-parameters-in-ecmwf-hres","text":"The following parameters are available for subsetting in ECMWF HRES , u10, ssr, str, sshf, slhf, d2m, v10, t2m, cp, lsp, swvl1,swvl2, swvl3, swvl4","title":"List of parameters in ECMWF HRES"},{"location":"user-guide/dataex_netcdf_subset/#list-of-parameters-in-ecmwf-ens","text":"The following parameters are available for subsetting in ECMWF ENS , cp_q5, cp_q25, cp_q50, cp_q75, cp_q95, t2m_q5, t2m_q25, t2m_q50, t2m_q75, t2m_q95, lsp_q5, lsp_q25, lsp_q50, lsp_q75, lsp_q95 There are five quantiles available for each parameter in ECMWF ENS .","title":"List of parameters in ECMWF ENS"},{"location":"user-guide/dataex_netcdf_subset/#example","text":"$ dataex_netcdf_subset.py --model_type hres --hres_params u10,swvl1,t2m --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc The model type input is case-insensitive. Here, only three parameters are provided. The hres_params denotes the parameters are intended for hres model. If the parameters are not provided then all model parameters are placed in the request. $ dataex_netcdf_subset.py --model_type ens --ens_params cp_q25 --latbounds 40.3 60.0 --lonbounds 90.0 120.0 --output /home/user/hres_subset.nc This one is for requesting netcdf data of model ens . Here, ens_params denotes the parameters are for model ens . Info Don't fret if you make a mistake by using the incorrect parameter option, the command refers to the model type selected and uses the related parameters.","title":"Example"},{"location":"user-guide/dataex_obs_data_summary/","text":"Fetch observation data summary CLI This script allows the user to fetch summary of observation data statistics from Dataex server. A sample of the information that is retrieved from the dataex server can be seen in the table below: country No. of Stations Sharing Data Data Available Period Total Records (Daily) % Missing Data Bangladesh 47 1981-01-01 to 2020-01-01 2830011 0.6% Nepal 16 1981-01-01 to 2021-01-01 1122690 12.1% Usage $ dataex_obs_data_summary.py --output <str> --output_type <str> Tip Option names too long, you can always use their short forms. Check using --help Options output_type : str json, table or csv output : str name of output file The default output type is table format. The two options are not required and can be ignored unless the user prefers csv or json. Example Tip There is no need for .csv or .json extension in the file name, it is appended by the program. $ dataex_obs_data_summary.py --output ./summary.csv --output_type csv Here, the observation summary data is downloaded in csv format. The file is saved as summary.csv in the current directory. $ dataex_obs_data_summary.py This would download the data in table format and display in that form on the terminal itself.","title":"Get observation data summary"},{"location":"user-guide/dataex_obs_data_summary/#fetch-observation-data-summary-cli","text":"This script allows the user to fetch summary of observation data statistics from Dataex server. A sample of the information that is retrieved from the dataex server can be seen in the table below: country No. of Stations Sharing Data Data Available Period Total Records (Daily) % Missing Data Bangladesh 47 1981-01-01 to 2020-01-01 2830011 0.6% Nepal 16 1981-01-01 to 2021-01-01 1122690 12.1%","title":"Fetch observation data summary CLI"},{"location":"user-guide/dataex_obs_data_summary/#usage","text":"$ dataex_obs_data_summary.py --output <str> --output_type <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_obs_data_summary/#options","text":"output_type : str json, table or csv output : str name of output file The default output type is table format. The two options are not required and can be ignored unless the user prefers csv or json.","title":"Options"},{"location":"user-guide/dataex_obs_data_summary/#example","text":"Tip There is no need for .csv or .json extension in the file name, it is appended by the program. $ dataex_obs_data_summary.py --output ./summary.csv --output_type csv Here, the observation summary data is downloaded in csv format. The file is saved as summary.csv in the current directory. $ dataex_obs_data_summary.py This would download the data in table format and display in that form on the terminal itself.","title":"Example"},{"location":"user-guide/dataex_obs_parameter_list/","text":"Get Parameter Info CLI This script allows the user to get station's parameter information such as ID number and name from Dataex server. This tool can download in either csv or json file. Info Observation station Id numbers can be obtained by executing dataex_obs_station_list.py . Usage $ dataex_obs_parameter_list.py --station_id <int> --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options output_type : str json, table or csv station_id : int station id output : str output filename If output_type is not specified then it defaults to table . Further, in this case, if output is also not specified, the data is displayed in tabular form in the terminal. Example $ dataex_obs_parameter_list.py --station_id 53 --output_type csv --output ./param_info.csv Here, data is downloaded in a csv file named as param_info.csv in the current directory. $ dataex_obs_parameter_list.py --station_id 53 Here, table is default and tabular data is displayed in the terminal.","title":"Download parameter list"},{"location":"user-guide/dataex_obs_parameter_list/#get-parameter-info-cli","text":"This script allows the user to get station's parameter information such as ID number and name from Dataex server. This tool can download in either csv or json file. Info Observation station Id numbers can be obtained by executing dataex_obs_station_list.py .","title":"Get Parameter Info CLI"},{"location":"user-guide/dataex_obs_parameter_list/#usage","text":"$ dataex_obs_parameter_list.py --station_id <int> --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_obs_parameter_list/#options","text":"output_type : str json, table or csv station_id : int station id output : str output filename If output_type is not specified then it defaults to table . Further, in this case, if output is also not specified, the data is displayed in tabular form in the terminal.","title":"Options"},{"location":"user-guide/dataex_obs_parameter_list/#example","text":"$ dataex_obs_parameter_list.py --station_id 53 --output_type csv --output ./param_info.csv Here, data is downloaded in a csv file named as param_info.csv in the current directory. $ dataex_obs_parameter_list.py --station_id 53 Here, table is default and tabular data is displayed in the terminal.","title":"Example"},{"location":"user-guide/dataex_obs_station_list/","text":"Get Station List CLI This script allows the user to get country's station information such as ID number and name from Dataex server. This tool can download output in either csv or json file or show it in tabular form. Info To get a list of country Id numbers, you can use dataex_list_country_info.py . This will help you know about the countries available in dataex. Usage $ dataex_obs_station_list.py --country_id <int> --not_empty --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options not_empty/empty : flag to get only those stations with data or all output_type : str json, table or csv country_id : int country id output : str output filename Each country has a number of stations with their own distinct id numbers. Using the empty/not_empty option, one can choose if they want to download information of stations having related observations or not. Info The empty and non-empty options are boolean flags which can be enabled or disabled. empty is the default state. Example $ dataex_obs_station_list.py --country_id 3 --non_empty --output_type csv --output ./station_info.csv This will download a list of observation stations and their related information for country with id number 3 and since output type is csv , the data will be stored in a csv file with name station_info.csv in the current directory. Since, non_empty flag is set, only those stations with observations are retrieved.","title":"List stations"},{"location":"user-guide/dataex_obs_station_list/#get-station-list-cli","text":"This script allows the user to get country's station information such as ID number and name from Dataex server. This tool can download output in either csv or json file or show it in tabular form. Info To get a list of country Id numbers, you can use dataex_list_country_info.py . This will help you know about the countries available in dataex.","title":"Get Station List CLI"},{"location":"user-guide/dataex_obs_station_list/#usage","text":"$ dataex_obs_station_list.py --country_id <int> --not_empty --output_type <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_obs_station_list/#options","text":"not_empty/empty : flag to get only those stations with data or all output_type : str json, table or csv country_id : int country id output : str output filename Each country has a number of stations with their own distinct id numbers. Using the empty/not_empty option, one can choose if they want to download information of stations having related observations or not. Info The empty and non-empty options are boolean flags which can be enabled or disabled. empty is the default state.","title":"Options"},{"location":"user-guide/dataex_obs_station_list/#example","text":"$ dataex_obs_station_list.py --country_id 3 --non_empty --output_type csv --output ./station_info.csv This will download a list of observation stations and their related information for country with id number 3 and since output type is csv , the data will be stored in a csv file with name station_info.csv in the current directory. Since, non_empty flag is set, only those stations with observations are retrieved.","title":"Example"},{"location":"user-guide/dataex_region_data_analysis/","text":"Get region data analysis CLI This script allows the user to download region data analysis of following models. HRES ENS SEAS Info To find the available reducer names for a particular model, you can use dataex_list_reducers.py . Usage $ dataex_region_data_analysis.py --model_type <str> --reducer <str> --asset_identifier <str> --unique_field <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help Options asset_identifier : str identifier for asset unique_field : str unique fields in asset output_format : str json or xlsx model_type : str Model names reducer : str name of reducer to use output : str output filename The model type input is case-insensitive. Hence, ENS or ens are both valid. Info User asset information such as asset identifier and unique field can obtained from dataex_list_user_assets.py . Example $ dataex_get_ecmwf_hres_region_data.py -r rainfall_daily_weighted_average -ai e02d7063-7b91-4bfd-00cb099860a0 -uf ADM2_EN -of xlsx -o ./hres_region_data.xlsx Here, the short option names are utilized. Since, model type is not explicitly specified, it defaults to HRES . The output is an excel file which will contain province wise data in different sheets.","title":"Download region specific forecast time series"},{"location":"user-guide/dataex_region_data_analysis/#get-region-data-analysis-cli","text":"This script allows the user to download region data analysis of following models. HRES ENS SEAS Info To find the available reducer names for a particular model, you can use dataex_list_reducers.py .","title":"Get region data analysis CLI"},{"location":"user-guide/dataex_region_data_analysis/#usage","text":"$ dataex_region_data_analysis.py --model_type <str> --reducer <str> --asset_identifier <str> --unique_field <str> --output_format <str> --output <str> Tip Option names too long, you can always use their short forms. Check using --help","title":"Usage"},{"location":"user-guide/dataex_region_data_analysis/#options","text":"asset_identifier : str identifier for asset unique_field : str unique fields in asset output_format : str json or xlsx model_type : str Model names reducer : str name of reducer to use output : str output filename The model type input is case-insensitive. Hence, ENS or ens are both valid. Info User asset information such as asset identifier and unique field can obtained from dataex_list_user_assets.py .","title":"Options"},{"location":"user-guide/dataex_region_data_analysis/#example","text":"$ dataex_get_ecmwf_hres_region_data.py -r rainfall_daily_weighted_average -ai e02d7063-7b91-4bfd-00cb099860a0 -uf ADM2_EN -of xlsx -o ./hres_region_data.xlsx Here, the short option names are utilized. Since, model type is not explicitly specified, it defaults to HRES . The output is an excel file which will contain province wise data in different sheets.","title":"Example"},{"location":"user-guide/delete_user_asset/","text":"In profile view page, click on \"Assets\" tab to view a list of your assets. ( DataEx > User Profile > Assets ) User assets will be displayed row by row in a table as shown in the image below. At the right end of each row there is a button with an ellipsis. Click on it to get a delete option. It will delete the corresponding asset displayed in that row.","title":"Delete user asset"},{"location":"user-guide/plot_netcdf_grads/","text":"Download subset netCDF from DataEx In DataeEx visit Forecast > Subset netCDF . Select forecast source, parameter and region values and proceed to download netCDF as shown in the image below: Plotting with GRADS Install Grads in windows or Linux. Manual | Download Ensure you have the following files in the folder where you are running the scripts: netCDF file containing forecast data downloaded from DataEx. Grads scripts (sample script provided for rainfall to customize as required for other parameters) Color bar file (cbar.gs) - also provided to download Shape file for overlay (for district or other layers) Sample file. (Copy the script and put in a file Plotgrads_pcp.gs or any preferred name). Or you can use your own script files. A sample code is shown in below. (Copy the code and put in a file Plotgrads_pcp.gs or any preferred name). To plot run command (use pbc or pbc depending on the mode of plotting (p=portrait or l=landscape) grads -pbc Plotgrads_pcp.gs You should see plots like the following:- Example Grads Script for plotting rainfall **************************************************************** ** This script plots downloaded subset of ECMWF HRES data ** RIMES ** **************************************************************** reinit **Provide the NC file downloaded from the DataEx. 'sdfopen ECMWF_HRES_NC_28.78N_25.85S_92.74E_88.2W.nc' **** DATA loop for plotting for daily accumulated**** i=1 k=1 day=24 while (i<41) j=i+4 ** SET the color bar and map 'set clopts 1 2 .10' 'set clevs 0.1 1 5 10 15 20 25 30 50 75 100 125 150 175' 'set ccols 0 5 13 3 10 7 12 8 2 6 9 14 4' 'set grads off' *'set mpdraw off' 'set gxout shaded' 'set mpdset hires' ***Plotting parameter.. for total precipitation (CP and LSP) if(i=1) 'd ((cp(t='j')-cp(t=2))+(lsp(t='j')-lsp(t=2)))*1000' ************* **Put the Shape file that you want to overlay here... **Only put the file name and no extension like .shp. **Ensure the location of the file is correct ************* *'set line 4 1 2' *'draw shp bhu_adm1' ******************* else 'd ((cp(t='j')-cp(t='i'))+(lsp(t='j')-lsp(t='i')))*1000' ******************* *'set line 4 1 2' *'draw shp bhu_adm1' ******************* endif ******************* *Plot cbar and add titles ******************* 'run cbar 1.1 0 4.3 2.0' 'set font 2' 'set strsiz .14' 'draw string 1.5 10.5 NHMS/INIT:ECM_00UTC' 'set font 1' 'draw string 4.4 8.99 Daily (24 Hrs) Accumulated Precipitation Forecast' 'draw string 4.5 8.69 Valid at: 20210702 + 'day' Hr (UTC)' 'set string 2 9 2 1' 'set strsiz .15' 'draw string 4.2 8.35 ********** DAY 'k' **********' 'draw string 4.2 2.55 (mm)' 'set font 2' 'set strsiz .10' 'draw string 2.2 1.75 Forecast initialized with 20210702 00 UTC data' day=day+24 'gxprint rain'k'.png png white' 'clear' k=k+1 i=i+4 endwhile quit","title":"Plotting subset netCDF with grads"},{"location":"user-guide/plot_netcdf_grads/#download-subset-netcdf-from-dataex","text":"In DataeEx visit Forecast > Subset netCDF . Select forecast source, parameter and region values and proceed to download netCDF as shown in the image below:","title":"Download subset netCDF from DataEx"},{"location":"user-guide/plot_netcdf_grads/#plotting-with-grads","text":"Install Grads in windows or Linux. Manual | Download Ensure you have the following files in the folder where you are running the scripts: netCDF file containing forecast data downloaded from DataEx. Grads scripts (sample script provided for rainfall to customize as required for other parameters) Color bar file (cbar.gs) - also provided to download Shape file for overlay (for district or other layers) Sample file. (Copy the script and put in a file Plotgrads_pcp.gs or any preferred name). Or you can use your own script files. A sample code is shown in below. (Copy the code and put in a file Plotgrads_pcp.gs or any preferred name). To plot run command (use pbc or pbc depending on the mode of plotting (p=portrait or l=landscape) grads -pbc Plotgrads_pcp.gs You should see plots like the following:-","title":"Plotting with GRADS"},{"location":"user-guide/plot_netcdf_grads/#example-grads-script-for-plotting-rainfall","text":"**************************************************************** ** This script plots downloaded subset of ECMWF HRES data ** RIMES ** **************************************************************** reinit **Provide the NC file downloaded from the DataEx. 'sdfopen ECMWF_HRES_NC_28.78N_25.85S_92.74E_88.2W.nc' **** DATA loop for plotting for daily accumulated**** i=1 k=1 day=24 while (i<41) j=i+4 ** SET the color bar and map 'set clopts 1 2 .10' 'set clevs 0.1 1 5 10 15 20 25 30 50 75 100 125 150 175' 'set ccols 0 5 13 3 10 7 12 8 2 6 9 14 4' 'set grads off' *'set mpdraw off' 'set gxout shaded' 'set mpdset hires' ***Plotting parameter.. for total precipitation (CP and LSP) if(i=1) 'd ((cp(t='j')-cp(t=2))+(lsp(t='j')-lsp(t=2)))*1000' ************* **Put the Shape file that you want to overlay here... **Only put the file name and no extension like .shp. **Ensure the location of the file is correct ************* *'set line 4 1 2' *'draw shp bhu_adm1' ******************* else 'd ((cp(t='j')-cp(t='i'))+(lsp(t='j')-lsp(t='i')))*1000' ******************* *'set line 4 1 2' *'draw shp bhu_adm1' ******************* endif ******************* *Plot cbar and add titles ******************* 'run cbar 1.1 0 4.3 2.0' 'set font 2' 'set strsiz .14' 'draw string 1.5 10.5 NHMS/INIT:ECM_00UTC' 'set font 1' 'draw string 4.4 8.99 Daily (24 Hrs) Accumulated Precipitation Forecast' 'draw string 4.5 8.69 Valid at: 20210702 + 'day' Hr (UTC)' 'set string 2 9 2 1' 'set strsiz .15' 'draw string 4.2 8.35 ********** DAY 'k' **********' 'draw string 4.2 2.55 (mm)' 'set font 2' 'set strsiz .10' 'draw string 2.2 1.75 Forecast initialized with 20210702 00 UTC data' day=day+24 'gxprint rain'k'.png png white' 'clear' k=k+1 i=i+4 endwhile quit","title":"Example Grads Script for plotting rainfall"},{"location":"user-guide/remove_error/","text":"Before uploading the shapefiles like GeoJson you must ensure the following: Shapefile is in Geographic Co-ordinate system Shapefile doesn't contain any invalid geometry Converting Shapefile to GeoJson To convert ESRI shapefile .shp to GeoJson format, you can make use of Mapshaper shown below. You can either drop the file directly or just click on the select button to upload from your local folder. After selecting the file you want to use, click on import to load the map data. After importing the shapefile, you can view the content stored in the shape file. Click on the simplify tab to open the simplification menu. Select a method from the options displayed and click apply. Then, using a horizontal scroll bar you can choose how much you would like to simplify the lines. After settling on the desired simplification level, just click on export tab to get a menu from which you can choose GeoJson and export to a GeoJson file. After exporting, you will have simplified your shapefile and converted it to a GeoJson format and reduced its size as well.","title":"Removing error from shapefiles"},{"location":"user-guide/remove_error/#converting-shapefile-to-geojson","text":"To convert ESRI shapefile .shp to GeoJson format, you can make use of Mapshaper shown below. You can either drop the file directly or just click on the select button to upload from your local folder. After selecting the file you want to use, click on import to load the map data. After importing the shapefile, you can view the content stored in the shape file. Click on the simplify tab to open the simplification menu. Select a method from the options displayed and click apply. Then, using a horizontal scroll bar you can choose how much you would like to simplify the lines. After settling on the desired simplification level, just click on export tab to get a menu from which you can choose GeoJson and export to a GeoJson file. After exporting, you will have simplified your shapefile and converted it to a GeoJson format and reduced its size as well.","title":"Converting Shapefile to GeoJson"},{"location":"user-guide/upload_user_asset/","text":"DataEx users can upload their own shape files and use the forecast analysis engine to perform analysis using the shapefile. Below, we explain how you can upload your shapefile. User assets Go to DataEx home page then click on user profile tab to get a drop down menu and select profile view. This will take you to your user profile page where you can see your user details, permissions, account settings and also assets. Click on the \"Assets\" tab to visit your assets list page. ( DataEx > User Profile > Assets ) You will see an asset list table with columns for the asset's name, identifier, record count, and unique fields . Each row consists of a different asset belonging to the user. Upload asset To upload an asset into DataEx, go back to profile view page and click on assets tab. There you can click on the add button. After clicking on the button, you will see a popup box for uploading files. Browse for the shapefile you want to upload and click on the upload button inside the popup box, You will now see a new row added to the asset view showing the file you just uploaded.","title":"Upload user asset"},{"location":"user-guide/upload_user_asset/#user-assets","text":"Go to DataEx home page then click on user profile tab to get a drop down menu and select profile view. This will take you to your user profile page where you can see your user details, permissions, account settings and also assets. Click on the \"Assets\" tab to visit your assets list page. ( DataEx > User Profile > Assets ) You will see an asset list table with columns for the asset's name, identifier, record count, and unique fields . Each row consists of a different asset belonging to the user.","title":"User assets"},{"location":"user-guide/upload_user_asset/#upload-asset","text":"To upload an asset into DataEx, go back to profile view page and click on assets tab. There you can click on the add button. After clicking on the button, you will see a popup box for uploading files. Browse for the shapefile you want to upload and click on the upload button inside the popup box, You will now see a new row added to the asset view showing the file you just uploaded.","title":"Upload asset"}]}